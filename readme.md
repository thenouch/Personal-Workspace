### Project Readme

#### Overview
Experienced analytics engineer focused on building scalable data products, end-to-end analytics pipelines, and stakeholder-ready insights. This workspace collects personal projects, reproducible analyses, and portfolio artifacts that demonstrate expertise in SQL, PySpark, Snowflake, data modeling, and visualization.

---

#### What You Will Find
- **Analytics Projects**: End-to-end pipelines and notebooks showcasing data ingestion, transformation, and modeling using SQL, PySpark, or dbt.  
- **Dashboard Examples**: Power BI and Tableau workbooks demonstrating KPI frameworks, DAX patterns, and visualization best practices.  
- **Modeling and Summary Tables**: Examples of summary tables and DAX patterns to avoid circular dependencies and support slicer-driven UX.  
- **Reusable Code**: SQL snippets, PySpark utilities, and Python notebooks for common tasks like aggregation, outlier detection, and cohort analysis.  

---

#### Highlights and Impact
- **Cross-Platform Experience** Snowflake, Palantir Foundry, Databricks, Redshift, and dbt used to design production-ready data solutions.  
- **Performance Improvements** Reduced processing time and improved data accuracy through optimized analytic pipelines.  
- **Business Outcomes** Supported product and go-to-market teams to deliver measurable improvements including improved market performance and revenue growth.  
- **Visualization and Reporting** Automated and scaled Power BI dashboards and advanced Tableau reports to drive operational insights.

---

#### How to Use This Workspace
1. **Browse by Folder**: Projects are grouped by domain â€” data engineering, analytics, visualization, interview prep.  
2. **Reproduce Analyses**: Each project contains a README with required inputs, SQL scripts or notebooks, and expected outputs. Look for environment notes and sample data links.  
3. **Run Locally**: Most notebooks are configured for local execution with sample CSVs; production-ready pipelines include Snowflake or Databricks connection notes.  
4. **Inspect DAX and Modeling Patterns**: See the Modeling folder for strategies to avoid circular dependencies, precomputed summary tables, and treatment patterns using TREATAS.

---

#### Tech Stack
- **Languages**: SQL, Python (Pandas, PySpark, Snowpark)  
- **Data Platforms**: Snowflake, Databricks, Palantir Foundry, Redshift  
- **Orchestration and Tools**: Airflow, dbt, SSIS  
- **Visualization**: Power BI, Tableau, QuickSight, Streamlit

---

#### Contact and Collaboration
- **Name** Nicolas Nouchi  
- **Email** nicolas.nouchi@outlook.com

---

